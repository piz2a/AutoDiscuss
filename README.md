# AutoDiscuss: Automated LLM-to-LLM Discussion for Enhanced Problem Solving
본 실험은 GPT와 DeepSeek와 같은 생성형 AI가 서로 대화를 주고받으며 문제를 해결할 때, 응답의 품질이 향상되는지와 비용 효율성이 어떻게 변화하는지를 분석하는 것을 목적으로 한다. 이를 통해 기존 1:1 인간-AI 상호작용의 한계를 넘어, AI 간 협업 기반 문제 해결 방식의 가능성과 한계를 탐색하고자 한다.
## 실험 목적
- 동일한 AI끼리 대화(GPT-GPT, DeepSeek-DeepSeek)를 통해 응답의 질이 향상되는가?
- 대화 횟수(N)를 증가시킬수록 응답 품질이 향상되는가?
- AI 간 협업 방식이 단독 응답 방식보다 비용 대비 효율적인가?
- GPT와 DeepSeek 간 응답 품질 및 비용의 차이는 어떻게 나타나는가?
## 실험 구성
- 모델 구성: GPT-4o, DeepSeek Chat 1.5 기반 동일 모델 간 대화 실험
- 대화 유형: 단독 응답, 1회 대화 후 응답, N회(예: 2회, 4회, 8회, 16회) 상호 대화 후 응답
- 문제 영역: 수학 (5문항), 글쓰기 (5문항), 프로그래밍 문제해결 (5문항)
  - 총 15문항 × 3 대화 방식 × 2 모델 = 90개의 실험 데이터 생성
## 평가 방법
- 응답 품질 평가 기준표: 문제마다 상이
- 비용 평가 기준: 전체 사용 토큰 수 × API 요금 단가
  - 모든 항목은 점수화하여 시각화 (예: 막대 그래프, 스파이더 차트 등)
## 실험 방식
- Python을 활용한 자동화 스크립트로 AI 간 대화 구현
- 프롬프트는 통일된 형식으로 제시 (예: “너희는 서로 실수할 수 있으니 꼼꼼히 대화하고 오류를 찾아보아라.”)
- 실험 결과는 응답 품질 점수와 비용을 이중 척도로 평가 및 비교
## 기대 효과
- AI 간 협력 기반 문제 해결 가능성 및 한계 검토
- 단일 모델의 반복 호출이 아닌 협업 구조의 성능 효율성 검증
- 프롬프트 엔지니어링 확장의 사례로서 연구 가치 확보
- 향후 자동화된 문제 해결 파이프라인 설계에 기초 데이터 제공
